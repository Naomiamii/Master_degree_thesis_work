{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1103c712-d851-487c-9113-7af95c0ef5cd",
   "metadata": {},
   "source": [
    "## Rete globale:\n",
    "* [Costruzione rete](#Costruzione-rete)\n",
    "    * [Creazione file node attribute](#Creazione-file-node-attribute)\n",
    "    * [Rete globale con account](#Rete-globale-con-account)\n",
    "    * [Algoritmi per analizzare solo la componente connessa più grande](#Componente-connessa)\n",
    "        * [Degree](#Degree)\n",
    "        * [Closeness](#Closeness)\n",
    "        * [Louvain](#Louvain)\n",
    "        * [Infomap](#Infomap)\n",
    "        * [Label propagation](#Label-propagation)\n",
    "        * [Leiden](#Leiden)\n",
    "    * [Analisi grafo completo](#grafo-completo)\n",
    "        * [Degree centrality](#Degree2)\n",
    "        * [Closeness](#Closeness2)\n",
    "        * [Louvain](#Louvain2)\n",
    "        * [Infomap](#Infomap2)\n",
    "        * [Label propagation](#Label-propagation2)\n",
    "        * [Leiden](#Leiden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6784ffb9-e54c-4226-ab67-9710a316decf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'graph_tool', 'infomap', 'wurlitzer', 'bayanpy'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'pyclustering', 'ASLPAw'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'infomap', 'wurlitzer'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import powerlaw\n",
    "import os\n",
    "\n",
    " \n",
    "import math\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from cdlib import algorithms\n",
    "from cdlib import evaluation\n",
    "from cdlib.algorithms import louvain\n",
    "from cdlib import NodeClustering\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d6496d-475d-44c5-a01e-40aeceb92866",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\naomi\\Documents\\tesi 2025\\prova ufficiale\\dataset\\\\'\n",
    "\n",
    "output_path = r\"C:\\Users\\naomi\\Documents\\tesi 2025\\prova ufficiale\\grafi\\IG\\general\\rete commenti sotto lo stesso post\\\\\"\n",
    "output_path2 = r\"C:\\Users\\naomi\\Documents\\tesi 2025\\prova ufficiale\\grafi\\IG\\general\\rete commenti sotto lo stesso post\\reti singole\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae828a2f-4899-4d8a-a373-34441eabdc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'General_IG.json', 'r', encoding = 'utf-8') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf67189-5644-4b51-a152-31dd4fbe3409",
   "metadata": {},
   "source": [
    "## Costruzione della rete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a355c-72bd-429a-a664-33494c2f7250",
   "metadata": {},
   "source": [
    "Per costruire la rete verranno effettuati i seguenti passaggi:\r\n",
    "\r\n",
    "1. I testi dei commenti saranno puliti da emoji, numeri e spazi vuoti.  \r\n",
    "2. Vengono create le singole reti per ogni account: due nodi vengono connessi ogniqualvolta si trovano sotto lo stesso post.  \r\n",
    "   Il peso degli archi è dato da:\r\n",
    "\r\n",
    "   $$\r\n",
    "   \\text{peso}(u_1, u_2) = \\frac{\\text{numero di co-occorrenze tra } u_1 \\text{ e } u_2}{\\max(\\text{count}_{u_1}, \\text{count}_{u_2})}\r\n",
    "   $$\r\n",
    "\r\n",
    "3. Vengono aperte tutte le singole reti per estrarre solo i nodi che appaiono insieme in almeno 2 account diversi.  \r\n",
    "4. Il peso sugli archi viene calcolato con la seguente formula:\r\n",
    "\r\n",
    "   $$\r\n",
    "   W_{i,j} = \\left( \\frac{1}{N} \\sum_{a=1}^{N} w_{i,j}^{(a)} \\right) \\cdot \\log(1 + A_{i,j}) \\cdot \\log(1 + C_{i,j})\r\n",
    "   $$\r\n",
    "\r\n",
    "Dove:\r\n",
    "\r\n",
    "- \\( W_{i,j} \\): peso composito tra i nodi \\( i \\) e \\( j \\)  \r\n",
    "- \\( w_{i,j}^{(a)} \\): peso normalizzato tra \\( i \\) e \\( j \\) nell’account \\( a \\)  \r\n",
    "- \\( N \\): numero totale di account  \r\n",
    "- \\( A_{i,j} \\): numero di account in cui la coppia \\( (i, j) \\) appare  \r\n",
    "- \\( C_{i,j} \\): numero totale di co-occorrenze tra \\( i \\) e \\( j \\) (valore assoluto)\r\n",
    "\\) (vae assoluto)\r\n",
    "assoluto)\r\n",
    "$\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4a5514-dfb0-4164-8a07-919c8b41fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U0001F1F2\"\n",
    "        u\"\\U0001F1F4\"\n",
    "        u\"\\U0001F620\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        u\"\\U0001F1E6\\U0001F1E8\"  # Bandiere di Instagram\n",
    "        u\"\\U0001F1E9\\U0001F1EA\"\n",
    "        u\"\\U0001F1EA\\U0001F1F8\"\n",
    "        u\"\\U0001F1EB\\U0001F1F7\"\n",
    "        u\"\\U0001F1EC\\U0001F1E7\"\n",
    "        u\"\\U0001F1EE\\U0001F1F9\"\n",
    "        u\"\\U0001F1EF\\U0001F1F5\"\n",
    "        u\"\\U0001F1F0\\U0001F1F7\"\n",
    "        u\"\\U0001F1F7\\U0001F1FA\"\n",
    "        u\"\\U0001F1FA\\U0001F1F8\"\n",
    "        u\"\\U0001F400-\\U0001F4F0\"  # Animali & Nature emoji\n",
    "        u\"\\U0001F980-\\U0001F9FF\"  # Animali emoji (alcune nuove aggiunte)\n",
    "        u\"\\U0001F493-\\U0001F49E\"  # Cuori colorati\n",
    "        u\"\\U0001F9E1-\\U0001F9FF\"  # Altri cuori\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # Simboli e pictogrammi\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # Emoticon\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # Simboli di trasporto e mappe\n",
    "        u\"\\U0001F700-\\U0001F77F\"  # Simboli alchemici e zodiacali\n",
    "        u\"\\U0001F780-\\U0001F7FF\"  # Emoji geometriche\n",
    "        u\"\\U0001F900-\\U0001F9FF\"  # Simboli e emoji vari\n",
    "        u\"\\U00002660-\\U000026FF\"  # Simboli vari\n",
    "        u\"\\U00002700-\\U000027BF\"  # Emoji vari\n",
    "        u\"\\U0001F300-\\U0001F9FF\"  # Simboli vari supplementari\n",
    "        u\"\\U00002B50-\\U00002B55\"  # Altre emoji\n",
    "        u\"\\U0001F91D-\\U0001F93F\"  # Emoji delle mani\n",
    "        \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fbe676-52cf-43b0-b1c1-d548cdf0b7b0",
   "metadata": {},
   "source": [
    "### Creazione file node attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f605a03-1877-47df-8723-be01df582e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raccogli i sentiment score\n",
    "sentiment_scores = []\n",
    "for account, posts in dataset.items():\n",
    "    for post_id, post_info in posts.items():\n",
    "        for interaction in post_info.get('interactions_post', []):\n",
    "            score = interaction.get('sentiment', {}).get('score')\n",
    "            if isinstance(score, (int, float)):\n",
    "                sentiment_scores.append(score)\n",
    "\n",
    "# Crea i bin\n",
    "df = pd.DataFrame({'sentiment_score': sentiment_scores})\n",
    "sentiment_bins = pd.cut(df['sentiment_score'], bins=3)\n",
    "bin_edges = sentiment_bins.cat.categories\n",
    "sentiment_labels = ['negative', 'neutral', 'positive']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99ea5686-90aa-46d2-b8be-32a70a58be75",
   "metadata": {},
   "source": [
    "def extract_mentions(text):\n",
    "    return re.findall(r'@(\\w+)', text)\n",
    "    \n",
    "def analyze_users(dataset, path, output_file, bin_edges):\n",
    "\n",
    "    user_data = defaultdict(lambda: {\n",
    "        'n_comments': 0,\n",
    "        'n_mentions': 0,\n",
    "        'unique_mentions': set(),\n",
    "        'mentioned_accounts': set(),\n",
    "        'sentiment_cats': Counter(),\n",
    "        'hate_scores': [],\n",
    "        'toxicity_scores': [],\n",
    "        'emoji_count': 0\n",
    "    })\n",
    "\n",
    "    for account_name, posts in dataset.items():\n",
    "        posts = posts.get('media', {})  \n",
    "        for post_id, post_data in posts.items():\n",
    "            for interaction in post_data.get('interactions_post', []):\n",
    "                author = interaction.get('user_name')\n",
    "                comment = interaction.get('comment', '')\n",
    "                if not author or not comment.strip() or comment.strip().isdigit():\n",
    "                    continue\n",
    "\n",
    "                user_data[author]['n_comments'] += 1\n",
    "\n",
    "                if emoji_pattern.search(comment):\n",
    "                    user_data[author]['emoji_count'] += 1\n",
    "\n",
    "                mentions = extract_mentions(comment)\n",
    "                user_data[author]['n_mentions'] += len(mentions)\n",
    "                user_data[author]['unique_mentions'].update(mentions)\n",
    "                if mentions:\n",
    "                    user_data[author]['mentioned_accounts'].add(account_name)\n",
    "\n",
    "                sentiment_score = interaction.get('sentiment', {}).get('score')\n",
    "                if sentiment_score is not None:\n",
    "                    if sentiment_score <= bin_edges[0].right:\n",
    "                        label = 'negative'\n",
    "                    elif sentiment_score <= bin_edges[1].right:\n",
    "                        label = 'neutral'\n",
    "                    else:\n",
    "                        label = 'positive'\n",
    "                    user_data[author]['sentiment_cats'][label] += 1\n",
    "\n",
    "                hate_score = interaction.get('hate')\n",
    "\n",
    "                if hate_score is not None:\n",
    "                    user_data[author]['hate_scores'].append(hate_score)\n",
    "\n",
    "                tox_score = interaction.get('toxicity', {}).get('toxicity')\n",
    "                if tox_score is not None:\n",
    "                    user_data[author]['toxicity_scores'].append(tox_score)\n",
    "\n",
    "    output_data = {}\n",
    "    for user, data in user_data.items():\n",
    "        n_comments = data['n_comments']\n",
    "        emoji_count = data['emoji_count']\n",
    "        emoji_ratio = round(emoji_count / n_comments, 4) if n_comments else 0.0\n",
    "\n",
    "        sentiment_total = sum(data['sentiment_cats'].values())\n",
    "\n",
    "        negative_count = data['sentiment_cats'].get('negative', 0)\n",
    "        neutral_count = data['sentiment_cats'].get('neutral', 0)\n",
    "        positive_count = data['sentiment_cats'].get('positive', 0)\n",
    "\n",
    "        negative_pct = round(negative_count / sentiment_total * 100, 2) if sentiment_total else 0.0\n",
    "        neutral_pct = round(neutral_count / sentiment_total * 100, 2) if sentiment_total else 0.0\n",
    "        positive_pct = round(positive_count / sentiment_total * 100, 2) if sentiment_total else 0.0\n",
    "\n",
    "        output_data[user] = {\n",
    "            'n_comments': n_comments,\n",
    "            'n_mentions': data['n_mentions'],\n",
    "            'n_unique_mentions': len(data['unique_mentions']),\n",
    "            'n_mentioned_accounts': len(data['mentioned_accounts']),\n",
    "\n",
    "            'negative_comment_count': negative_count,\n",
    "            'neutral_comment_count': neutral_count,\n",
    "            'positive_comment_count': positive_count,\n",
    "\n",
    "            'negative_comment_percentage': negative_pct,\n",
    "            'neutral_comment_percentage': neutral_pct,\n",
    "            'positive_comment_percentage': positive_pct,\n",
    "            \n",
    "            'avg_hate': round(sum(data['hate_scores']) / len(data['hate_scores']), 4) if data['hate_scores'] else None,\n",
    "            'avg_toxicity': round(sum(data['toxicity_scores']) / len(data['toxicity_scores']), 4) if data['toxicity_scores'] else None,\n",
    "            'emoji_count': emoji_count,\n",
    "            'emoji_ratio': emoji_ratio\n",
    "        }\n",
    "\n",
    "\n",
    "    with open(path + output_file, 'w', encoding='utf-8') as jsonfile:\n",
    "        json.dump(output_data, jsonfile, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"✅ File salvato in formato JSON: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94c444-533d-4d41-8ba2-a7d4e807094f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f064257c-11ed-4c02-9b7e-cab29a350512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def extract_mentions(text):\n",
    "    return re.findall(r'@(\\w+)', text)\n",
    "\n",
    "def analyze_users(dataset, path, output_file, bin_edges, emoji_pattern):\n",
    "\n",
    "    user_data = defaultdict(lambda: {\n",
    "        'n_comments': 0,\n",
    "        'n_mentions': 0,\n",
    "        'unique_mentions': set(),\n",
    "        'mentioned_accounts': set(),\n",
    "        'sentiment_cats': Counter(),\n",
    "        'hate_scores': [],\n",
    "        'toxicity_scores': [],\n",
    "        'emoji_count': 0,\n",
    "        'sentiment_scores': []  # <-- per memorizzare tutti i punteggi\n",
    "    })\n",
    "\n",
    "    for account_name, posts in dataset.items():\n",
    "        for post_id, post_data in posts.items():\n",
    "            for interaction in post_data.get('interactions_post', []):\n",
    "                author = interaction.get('user_name')\n",
    "                comment = interaction.get('comment', '')\n",
    "                if not author or not comment.strip() or comment.strip().isdigit():\n",
    "                    continue\n",
    "\n",
    "                user_data[author]['n_comments'] += 1\n",
    "\n",
    "                if emoji_pattern.search(comment):\n",
    "                    user_data[author]['emoji_count'] += 1\n",
    "\n",
    "                mentions = extract_mentions(comment)\n",
    "                user_data[author]['n_mentions'] += len(mentions)\n",
    "                user_data[author]['unique_mentions'].update(mentions)\n",
    "                if mentions:\n",
    "                    user_data[author]['mentioned_accounts'].add(account_name)\n",
    "\n",
    "                sentiment_score = interaction.get('sentiment', {}).get('score')\n",
    "                hate = interaction.get('hate')\n",
    "\n",
    "                hate_score = None\n",
    "                if hate:\n",
    "                    # Caso 1: formato {\"label\": \"hateful\", \"score\": 0.88}\n",
    "                    if 'label' in hate and 'score' in hate:\n",
    "                        if hate['label'] == 'hateful':\n",
    "                            hate_score = hate['score']\n",
    "                    \n",
    "                    # Caso 2: formato {\"hateful\": 0.02, \"non-hateful\": 0.97}\n",
    "                    elif 'hateful' in hate:\n",
    "                        hate_score = hate['hateful']\n",
    "                hate = interaction.get('hate')\n",
    "                \n",
    "                hate_score = None\n",
    "                if hate:\n",
    "                    # Caso 1: formato {\"label\": \"hateful\", \"score\": 0.88}\n",
    "                    if 'label' in hate and 'score' in hate:\n",
    "                        if hate['label'] == 'hateful':\n",
    "                            hate_score = hate['score']\n",
    "                        elif hate['label'] == 'non-hateful':\n",
    "                            hate_score = 1 - hate['score']\n",
    "                    \n",
    "                    # Caso 2: formato {\"hateful\": 0.02, \"non-hateful\": 0.97}\n",
    "                    elif 'hateful' in hate:\n",
    "                        hate_score = hate['hateful']\n",
    "                \n",
    "                                \n",
    "                if sentiment_score is not None:\n",
    "                    # etichettatura preliminare in base al sentiment\n",
    "                    if sentiment_score <= bin_edges[0].right:\n",
    "                        label = 'negative'\n",
    "                    elif sentiment_score <= bin_edges[1].right:\n",
    "                        label = 'neutral'\n",
    "                    else:\n",
    "                        label = 'positive'\n",
    "                \n",
    "                    # riclassificazione: se neutro ma con hate alto → negativo\n",
    "                    if label == 'neutral' and hate_score is not None and hate_score > 0.5:\n",
    "                        label = 'negative'\n",
    "                \n",
    "                    user_data[author]['sentiment_scores'].append(sentiment_score)\n",
    "                    user_data[author]['sentiment_cats'][label] += 1\n",
    "                \n",
    "                if hate_score is not None:\n",
    "                    user_data[author]['hate_scores'].append(hate_score)\n",
    "                \n",
    "                tox_score = interaction.get('toxicity', {}).get('toxicity')\n",
    "                if tox_score is not None:\n",
    "                    user_data[author]['toxicity_scores'].append(tox_score)\n",
    "\n",
    "\n",
    "    output_data = {}\n",
    "    for user, data in user_data.items():\n",
    "        n_comments = data['n_comments']\n",
    "        emoji_count = data['emoji_count']\n",
    "        emoji_ratio = round(emoji_count / n_comments, 4) if n_comments else 0.0\n",
    "\n",
    "        sentiment_total = sum(data['sentiment_cats'].values())\n",
    "        negative_count = data['sentiment_cats'].get('negative', 0)\n",
    "        neutral_count = data['sentiment_cats'].get('neutral', 0)\n",
    "        positive_count = data['sentiment_cats'].get('positive', 0)        \n",
    "    \n",
    "        negative_pct = round(negative_count / sentiment_total * 100, 2) if sentiment_total else 0.0\n",
    "        neutral_pct = round(neutral_count / sentiment_total * 100, 2) if sentiment_total else 0.0\n",
    "        positive_pct = round(positive_count / sentiment_total * 100, 2) if sentiment_total else 0.0\n",
    "        avg_hate = round(sum(data['hate_scores']) / len(data['hate_scores']), 4) if data['hate_scores'] else None\n",
    "        \n",
    "\n",
    "        if negative_count > positive_count:\n",
    "            node_label = 'negative'\n",
    "        elif negative_count == positive_count:\n",
    "            if neutral_count > 0 and avg_hate is not None and avg_hate > 0.5:\n",
    "                node_label = 'negative'\n",
    "            else:\n",
    "                node_label = 'positive' \n",
    "        else:\n",
    "            node_label = 'positive'\n",
    "        \n",
    "        \n",
    "    # Salva dati dell'utentea\n",
    "        output_data[user] = {\n",
    "            'n_comments': n_comments,\n",
    "            'n_mentions': data['n_mentions'],\n",
    "            'n_unique_mentions': len(data['unique_mentions']),\n",
    "            'n_mentioned_accounts': len(data['mentioned_accounts']),\n",
    "            'negative_comment_count': negative_count,\n",
    "            'neutral_comment_count': neutral_count,\n",
    "            'positive_comment_count': positive_count,\n",
    "            'negative_comment_percentage': negative_pct,\n",
    "            'neutral_comment_percentage': neutral_pct,\n",
    "            'positive_comment_percentage': positive_pct,\n",
    "            'avg_hate': avg_hate,\n",
    "            'avg_toxicity': round(sum(data['toxicity_scores']) / len(data['toxicity_scores']), 4) if data['toxicity_scores'] else None,\n",
    "            'emoji_count': emoji_count,\n",
    "            'emoji_ratio': emoji_ratio,\n",
    "            'node_label': node_label\n",
    "        }\n",
    "\n",
    "    # Salva file JSON\n",
    "    with open(path + output_file, 'w', encoding='utf-8') as jsonfile:\n",
    "        json.dump(output_data, jsonfile, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"✅ File salvato in formato JSON: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "853b210a-9eb7-4f82-a911-c7b20b96f1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File salvato in formato JSON: nodes_attributes_general_IG_nuovo2.json\n"
     ]
    }
   ],
   "source": [
    "analyze_users(dataset, output_path, 'nodes_attributes_general_IG_nuovo2.json', bin_edges, emoji_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad7b876-d19a-4eba-b8d6-31ac4ac08f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_spaces_or_numbers = re.compile(r'^[\\s\\d]*$')\n",
    "\n",
    "def clean_comments(dataset):\n",
    "    stats = {}\n",
    "\n",
    "    for account, posts in dataset.items():\n",
    "        cleaned = 0\n",
    "        removed = 0\n",
    "\n",
    "        for post_id in posts:\n",
    "            post = posts[post_id]\n",
    "            new_comments = []\n",
    "\n",
    "            for comment_info in post['interactions_post']:\n",
    "                original_comment = comment_info['comment']\n",
    "                cleaned_comment = emoji_pattern.sub('', original_comment).strip()\n",
    "\n",
    "                # Se è vuoto o contiene solo spazi/numeri → da eliminare\n",
    "                if not cleaned_comment or only_spaces_or_numbers.fullmatch(cleaned_comment):\n",
    "                    removed += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    if cleaned_comment != original_comment:\n",
    "                        cleaned += 1  # Pulito da emoji, ma mantenuto\n",
    "                    comment_info['comment'] = cleaned_comment\n",
    "                    new_comments.append(comment_info)\n",
    "\n",
    "            post['interactions_post'] = new_comments\n",
    "\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e22d26-f80d-4a3e-87c1-5401e8077804",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pulito = clean_comments(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "de8d5412-ae57-45fc-95c2-0d4a271e2525",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for account, posts in dataset_pulito.items():\n",
    "    author_post_count = defaultdict(set)      # author -> set di post_id (solo per questo account)\n",
    "    user_pairs_count = defaultdict(int)       # (u1, u2) -> co-presenza count\n",
    "\n",
    "    # Fase 1: conteggio per l'account corrente\n",
    "    for post_id, post_data in posts.items():\n",
    "        interactions = post_data['interactions_post']\n",
    "        authors = set(interaction['user_name'] for interaction in interactions)\n",
    "\n",
    "        for author in authors:\n",
    "            author_post_count[author].add(post_id)\n",
    "\n",
    "        for u1, u2 in combinations(sorted(authors), 2):\n",
    "            user_pairs_count[(u1, u2)] += 1\n",
    "\n",
    "    # Fase 2: salvataggio file per l'account corrente\n",
    "    file_path = os.path.join(output_path2, f'general_IG_{account}_with_normalized_weight_comment_cleaned_big_graph.edgelist')\n",
    "    with open(file_path, 'w') as grafo:\n",
    "        for (u1, u2), count in user_pairs_count.items():\n",
    "            if count > 3:\n",
    "                max_posts = max(len(author_post_count[u1]), len(author_post_count[u2]))\n",
    "                if max_posts > 0:\n",
    "                    weight = count / max_posts\n",
    "                    grafo.write(f\"{u1} {u2} {weight:.4f} {account}\\n\")\n",
    "\n",
    "    # Opzionale: pulizia esplicita delle strutture dati per questo account\n",
    "    del author_post_count\n",
    "    del user_pairs_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ad9139b9-f551-4c33-ad51-7e5ff20aa217",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Percorso dove si trovano i file\n",
    "input_folder = output_path2  # stesso path dove li hai salvati\n",
    "output_file = os.path.join(output_path2, \"general_IG_merged_edges_with_global_weights_big_graph.edgelist\")\n",
    "\n",
    "# Dizionario: (u1, u2) -> set di account in cui compare\n",
    "pair_to_accounts = defaultdict(set)\n",
    "\n",
    "# Dizionario: (u1, u2, account) -> peso_vecchio\n",
    "pair_weight_per_account = dict()\n",
    "\n",
    "# Legge tutti i file edgelist nell'input_folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\"_with_normalized_weight_comment_cleaned_big_graph.edgelist\"):\n",
    "        account = filename.replace(\"general_IG_\", \"\").replace(\"_with_normalized_weight_comment_cleaned_big_graph.edgelist\", \"\")\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 4:\n",
    "                    continue  # salta righe mal formattate\n",
    "\n",
    "                u1, u2, weight_str, acc_from_file = parts\n",
    "                weight = float(weight_str)\n",
    "\n",
    "                # Ordinamento garantito (u1, u2) per coerenza\n",
    "                key = tuple(sorted((u1, u2)))\n",
    "\n",
    "                pair_to_accounts[key].add(account)\n",
    "                pair_weight_per_account[(key[0], key[1], account)] = weight\n",
    "\n",
    "# Scrittura file finale\n",
    "with open(output_file, \"w\") as out:\n",
    "    for (u1, u2), accounts in pair_to_accounts.items():\n",
    "        peso_nuovo = len(accounts)  # in quanti account appare la coppia\n",
    "        for account in accounts:\n",
    "            peso_vecchio = pair_weight_per_account.get((u1, u2, account))\n",
    "            if peso_vecchio is not None:\n",
    "                out.write(f\"{u1} {u2} {peso_vecchio:.4f} {peso_nuovo}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bffd0e74-6c39-4c15-a6db-fef5349e5c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coppie presenti in 2 account: 5634\n",
      "Coppie presenti in 3 account: 78745\n",
      "Coppie presenti in 4 account: 3\n",
      "Coppie presenti in 5 account: 276\n",
      "Coppie presenti in 6 account: 2553\n",
      "Coppie presenti in 8 account: 67\n",
      "Coppie presenti in 9 account: 588\n",
      "Coppie presenti in 10 account: 1\n",
      "Coppie presenti in 11 account: 11\n",
      "Coppie presenti in 12 account: 183\n",
      "Coppie presenti in 14 account: 9\n",
      "Coppie presenti in 15 account: 53\n",
      "Coppie presenti in 18 account: 18\n",
      "Coppie presenti in 20 account: 1\n",
      "Coppie presenti in 21 account: 4\n",
      "Coppie presenti in 27 account: 1\n",
      "Coppie presenti in 30 account: 1\n",
      "Coppie presenti in 33 account: 1\n"
     ]
    }
   ],
   "source": [
    "# Dizionario per tenere il conteggio: quante coppie compaiono in X account\n",
    "frequency_count = defaultdict(int)\n",
    "\n",
    "for pair, accounts in pair_to_accounts.items():\n",
    "    freq = len(accounts)  # in quanti account compare la coppia\n",
    "    frequency_count[freq] += 1\n",
    "\n",
    "# Stampa ordinata per frequenza\n",
    "for freq in sorted(frequency_count.keys()):\n",
    "    print(f\"Coppie presenti in {freq} account: {frequency_count[freq]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ca649927-85ad-48ce-9dce-6c7cbf6974f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filtered_file = os.path.join(output_path, \"general_IG_merged_edges_filtered_min2account_big_graph.edgelist\")\n",
    "\n",
    "with open(output_filtered_file, \"w\") as out:\n",
    "    for (u1, u2), accounts in pair_to_accounts.items():\n",
    "        peso_nuovo = len(accounts)\n",
    "        if peso_nuovo < 1:\n",
    "            continue  # salta le coppie che appaiono in un solo account\n",
    "\n",
    "        for account in accounts:\n",
    "            peso_vecchio = pair_weight_per_account.get((u1, u2, account))\n",
    "            if peso_vecchio is not None:\n",
    "                out.write(f\"{u1} {u2} {peso_vecchio:.4f} {peso_nuovo}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7bcf88ae-0b17-480b-b048-38b3fea20a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per calcolare il peso composito moltiplicativo\n",
    "def compute_multiplicative_weight(pair, weights_by_account, account_count, absolute_counts, N):\n",
    "    normalized_weights = [\n",
    "        weights[pair]\n",
    "        for acc, weights in weights_by_account.items()\n",
    "        if pair in weights\n",
    "    ]\n",
    "    if not normalized_weights:\n",
    "        return 0\n",
    "    avg_weight = sum(normalized_weights) / N\n",
    "    A_ij = account_count.get(pair, 0)\n",
    "    C_ij = absolute_counts.get(pair, 0)\n",
    "    weight = avg_weight * math.log(1 + A_ij) * math.log(1 + C_ij)\n",
    "    return round(weight, 4)\n",
    "\n",
    "# === Parte 1: lettura dei file ===\n",
    "input_folder = output_path2\n",
    "output_file = os.path.join(output_path2, \"general_IG_merged_edges_with_global_weights_big_graph.edgelist\")\n",
    "\n",
    "# Strutture dati\n",
    "pair_to_accounts = defaultdict(set)\n",
    "pair_weight_per_account = dict()\n",
    "weights_by_account = defaultdict(dict)\n",
    "absolute_counts = defaultdict(int)\n",
    "\n",
    "# Legge tutti i file edgelist\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\"_with_normalized_weight_comment_cleaned_big_graph.edgelist\"):\n",
    "        account = filename.replace(\"general_IG\", \"\").replace(\"_with_normalized_weight_comment_cleaned_big_graph.edgelist\", \"\")\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 4:\n",
    "                    continue\n",
    "\n",
    "                u1, u2, weight_str, acc_from_file = parts\n",
    "                weight = float(weight_str)\n",
    "                key = tuple(sorted((u1, u2)))\n",
    "\n",
    "                pair_to_accounts[key].add(account)\n",
    "                pair_weight_per_account[(key[0], key[1], account)] = weight\n",
    "                weights_by_account[account][key] = weight\n",
    "                absolute_counts[key] += 1  # conta quante volte compare la coppia (su tutti gli account)\n",
    "\n",
    "# Conta quanti account per coppia\n",
    "account_count = {pair: len(accounts) for pair, accounts in pair_to_accounts.items()}\n",
    "total_accounts = len(weights_by_account)\n",
    "\n",
    "# === Parte 2: scrittura del file con pesi globali ===\n",
    "with open(output_file, \"w\") as out:\n",
    "    for (u1, u2), accounts in pair_to_accounts.items():\n",
    "        key = (u1, u2)\n",
    "        peso_globale = compute_multiplicative_weight(key, weights_by_account, account_count, absolute_counts, total_accounts)\n",
    "        out.write(f\"{u1} {u2} {peso_globale:.4f}\\n\")\n",
    "\n",
    "# === Parte 3: scrittura file filtrato (solo coppie con almeno 2 account) ===\n",
    "output_filtered_file = os.path.join(output_path, \"general_IG_global_weight_big_graph.edgelist\")\n",
    "\n",
    "with open(output_filtered_file, \"w\") as out:\n",
    "    for (u1, u2), accounts in pair_to_accounts.items():\n",
    "        if len(accounts) < 1:\n",
    "            continue\n",
    "        key = (u1, u2)\n",
    "        peso_globale = compute_multiplicative_weight(key, weights_by_account, account_count, absolute_counts, total_accounts)\n",
    "        out.write(f\"{u1} {u2} {peso_globale:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c519c2-ebc5-4130-9f76-6c95bb6b838e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff637cd0-f009-4ef0-93cc-348bae7e647e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31030390-8d3b-48fc-9f21-2126b163077c",
   "metadata": {},
   "source": [
    "### Rete globale con account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cee66232-9b10-4493-bbb2-0342ca3c2522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodi nella rete: 9923\n",
      "Archi nella rete: 88149\n",
      "Density: 0.0017906271761623156\n",
      "Assortativity: -0.28375263025762804\n"
     ]
    }
   ],
   "source": [
    "g = nx.Graph()\n",
    "with open(output_path+'general_IG_global_weight_big_graph.edgelist') as f:\n",
    "    for l in f:\n",
    "        l = l.rsplit()\n",
    "        if len(l)==3:\n",
    "            g.add_edge(l[0], l[1], weight=float(l[2]))\n",
    "\n",
    "\n",
    "with open(output_path + 'nodes_attributes_general_IG_nuovo2.json', 'r') as f:\n",
    "    node_data = json.load(f)\n",
    "\n",
    "# Aggiungi attributi ai nodi presenti nella rete\n",
    "for node, attributes in node_data.items():\n",
    "    if node in g.nodes:\n",
    "        g.nodes[node].update(attributes)\n",
    "\n",
    "print(\"Nodi nella rete:\", g.number_of_nodes())\n",
    "print(\"Archi nella rete:\", g.number_of_edges())\n",
    "print(\"Density:\", nx.density(g))\n",
    "print(\"Assortativity:\", nx.degree_assortativity_coefficient(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8422192-8d3c-4cbc-a2a4-7f7b0ddb4195",
   "metadata": {},
   "source": [
    "### Componente connessa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2496ca4-3ea6-4f6c-adea-c52c1316555c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9825"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_ccG = max(nx.connected_components(g), key=len)\n",
    "\n",
    "G_connected = g.subgraph(largest_ccG).copy()\n",
    "len(G_connected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407effbc-51b8-438f-bae0-ae41f0fcbb6d",
   "metadata": {},
   "source": [
    "#### Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3999dca3-4275-4391-8158-e8dab1f5f4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('general_30', 1795),\n",
       " ('user_339221', 1615),\n",
       " ('general_14', 1286),\n",
       " ('general_33', 1247),\n",
       " ('general_39', 1231),\n",
       " ('user_393808', 1182),\n",
       " ('user_472248', 980),\n",
       " ('user_370283', 919),\n",
       " ('user_625432', 889),\n",
       " ('user_229255', 853)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree_sequence = sorted(((n,d) for n, d in G_connected.degree()), reverse=False, key=lambda item: -item[1])\n",
    "degree_sequence[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c266fdef-26af-45aa-b38a-9e5ed6bc45e9",
   "metadata": {},
   "source": [
    "#### Closeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29299122-5dd1-40b2-97e0-69a151b7ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness = nx.closeness_centrality(G_connected) # compute the closeness centraliry of all nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72424453-5918-48f4-b26e-433718a9ba67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('general_30', 0.6002299731697969),\n",
       " ('user_339221', 0.56759695541863),\n",
       " ('user_393808', 0.558288770053476),\n",
       " ('general_14', 0.5357509408142319),\n",
       " ('general_33', 0.5244474212993971),\n",
       " ('general_39', 0.5216522318454364),\n",
       " ('user_572416', 0.5129380936783492),\n",
       " ('user_472248', 0.5089372765680859),\n",
       " ('user_370283', 0.5063045586808923),\n",
       " ('user_333699', 0.5058139534883721),\n",
       " ('user_625432', 0.5051612903225806),\n",
       " ('healthy_16', 0.5016015374759769),\n",
       " ('user_474081', 0.5),\n",
       " ('user_229789', 0.4998404085541015),\n",
       " ('user_291841', 0.49793322734499207),\n",
       " ('user_158318', 0.4954128440366973),\n",
       " ('user_426370', 0.4941621962764279),\n",
       " ('user_482802', 0.4922980194907262),\n",
       " ('user_229255', 0.4922980194907262),\n",
       " ('user_366960', 0.49214330609679446),\n",
       " ('user_237813', 0.49198868991517436),\n",
       " ('general_27', 0.49106302916274697),\n",
       " ('user_458439', 0.4909090909090909),\n",
       " ('user_255658', 0.48952797749296656),\n",
       " ('user_351537', 0.48922211808809746),\n",
       " ('general_35', 0.48845913911416095),\n",
       " ('user_327150', 0.4880024929884699),\n",
       " ('user_680020', 0.4863354037267081),\n",
       " ('user_594371', 0.48618441477801927),\n",
       " ('user_670698', 0.4860335195530726)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = [(k, v) for k, v in sorted(closeness.items(), key=lambda item: -item[1])]\n",
    "ranks[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef221e-e059-4d6e-a995-c70b87263479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f77f252-8b70-45f6-a25b-8c653ea06eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_algo(graph, algo, algo_name):\n",
    "    scd = evaluation.avg_transitivity(graph, algo)\n",
    "    scd_hub = evaluation.hub_dominance(graph, algo)\n",
    "    ave = evaluation.avg_embeddedness(graph, algo)\n",
    "    cond = evaluation.conductance(graph, algo)\n",
    "    mod = evaluation.newman_girvan_modularity(graph, algo)\n",
    "    int_dens = evaluation.internal_edge_density(graph, algo)\n",
    "    \n",
    "    print(f\"Results with {algo_name} algorithm\")\n",
    "    print(\"Transitivity:\", scd.score)\n",
    "    print(\"Hub Dominance:\", scd_hub.score)\n",
    "    print(\"Embeddedness:\", ave.score)\n",
    "    print(\"Conductance:\", cond.score)\n",
    "    print(\"Modularity:\", mod.score)\n",
    "    print(\"Internal Edge Density:\", int_dens.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab600fc-ca47-43a0-916f-6b7b61a6a130",
   "metadata": {},
   "source": [
    "### Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750d7986-49ee-46b8-ae5d-ccdc8f77774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_coms2 = algorithms.louvain(G_connected, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed86d0b-2cd7-471a-a742-580d6a5ab25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "louvain_coms2.overlap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "042740c7-ea00-4a53-aa79-c9ec546b0b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "louvain_coms2.node_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66fd5704-8f02-440f-9942-0893f0422410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "louvain_communities2 = louvain_coms2.communities\n",
    "len(louvain_communities2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c92e7939-b79d-4bd6-9a10-522ed70e5a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Louvain algorithm\n",
      "Transitivity: 0.3086605570331933\n",
      "Hub Dominance: 0.7616555846804567\n",
      "Embeddedness: 0.6903677818529265\n",
      "Conductance: 0.3920756803182934\n",
      "Modularity: 0.44188390437310865\n",
      "Internal Edge Density: 0.42452548003777296\n"
     ]
    }
   ],
   "source": [
    "evaluation_algo(G_connected, louvain_coms2, 'Louvain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09acbb5f-8946-44a8-add5-0c818c142e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduct_communities_louvain2 = [c for c in louvain_communities2 if len(c) >= 5]\n",
    "len(reduct_communities_louvain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0095f1eb-15a0-45de-9ad5-d037244a7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ottieni l'insieme dei nodi che compongono tutte le comunità\n",
    "nodes_in_communities_louvain = set(node for community in reduct_communities_louvain2 for node in community)\n",
    "\n",
    "# 2. Crea un sottografo a partire dal grafo originale\n",
    "subgraph = louvain_coms2.graph.subgraph(nodes_in_communities_louvain).copy()\n",
    "\n",
    "# 3. Crea il NodeClustering usando il sottografo\n",
    "reduct_nodeclustering_louvain2 = NodeClustering(\n",
    "    communities=reduct_communities_louvain2,\n",
    "    graph=subgraph,  # <--- USA il sottografo, non l'intero grafo\n",
    "    method_name=louvain_coms2.method_name + \"_reduct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "940595b7-98d5-49b5-8e62-ec1907e33ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Louvain algorithm\n",
      "Transitivity: 0.5223486349792501\n",
      "Hub Dominance: 0.5966479125361577\n",
      "Embeddedness: 0.809340348776747\n",
      "Conductance: 0.3032562795130093\n",
      "Modularity: 0.43828413818466955\n",
      "Internal Edge Density: 0.0261200431408466\n"
     ]
    }
   ],
   "source": [
    "evaluation_algo(G_connected, reduct_nodeclustering_louvain2, 'Louvain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46222e21-0e50-4cbd-a21d-9663d82321f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caaee20e-7832-4e66-a790-5e0cd883cc96",
   "metadata": {},
   "source": [
    "### Infomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13a02c27-b255-4c98-9e8a-311bbfe42bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "infomap_coms2 = algorithms.infomap(G_connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66c16602-7ff3-4fc0-8d70-4b906e5690dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'igraph': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infomap_coms2.method_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd6faad2-a7d2-4e0b-9a7c-56a98ebe9749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infomap_coms2.overlap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd37b053-a02b-470f-8854-fc626f4cc289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FitnessResult(min=1.0, max=37.3984962406015, score=4.842436923703746, std=7.524900045787024)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infomap_coms2.average_internal_degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a17c90c-7edb-407c-8d03-58e7f5b44f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infomap_communities2 = infomap_coms2.communities\n",
    "len(infomap_communities2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcf04a1b-1fa7-4d74-990e-db8889aea143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Infomap algorithm\n",
      "Transitivity: 0.2371875599065822\n",
      "Hub Dominance: 0.9274527016693861\n",
      "Embeddedness: 0.7256416110047085\n",
      "Conductance: 0.4374888907433958\n",
      "Modularity: 0.3980117237262148\n",
      "Internal Edge Density: 0.4018056003295724\n"
     ]
    }
   ],
   "source": [
    "evaluation_algo(G_connected, infomap_coms2, 'Infomap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d44c41e4-0059-43a4-ad0e-4d806c036a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduct_communities_infomap2 = [c for c in infomap_communities2 if len(c) >= 5]\n",
    "len(reduct_communities_infomap2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98266222-e966-420d-8690-a28ec9982179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ottieni l'insieme dei nodi che compongono tutte le comunità\n",
    "nodes_in_communities_infomap2 = set(node for community in reduct_communities_infomap2 for node in community)\n",
    "\n",
    "# 2. Crea un sottografo a partire dal grafo originale\n",
    "subgraph = infomap_coms2.graph.subgraph(nodes_in_communities_infomap2).copy()\n",
    "\n",
    "# 3. Crea il NodeClustering usando il sottografo\n",
    "reduct_nodeclustering_infomap2 = NodeClustering(\n",
    "    communities=reduct_communities_infomap2,\n",
    "    graph=subgraph,  # <--- USA il sottografo, non l'intero grafo\n",
    "    method_name=infomap_coms2.method_name + \"_reduct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37c9334c-e53a-4137-945f-066a49ebb867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Infomap algorithm\n",
      "Transitivity: 0.3809375962136017\n",
      "Hub Dominance: 0.8834846420750745\n",
      "Embeddedness: 0.7833116109402223\n",
      "Conductance: 0.41792948830793586\n",
      "Modularity: 0.3921227522917243\n",
      "Internal Edge Density: 0.08976859042830321\n"
     ]
    }
   ],
   "source": [
    "evaluation_algo(G_connected, reduct_nodeclustering_infomap2, 'Infomap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f38a7ee-ab58-4e49-923c-5120578b1028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb1cb63a-9032-46a1-9edf-7644b51e4e7a",
   "metadata": {},
   "source": [
    "### Label propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31455d5d-a172-4acd-a249-5dc113c1b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_coms2 = algorithms.label_propagation(G_connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dce7d470-8f74-4f89-b12f-48ed303b4ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_coms2.overlap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "180096eb-5f74-462d-919e-fc8bd652fbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FitnessResult(min=1.0, max=26.328827037773358, score=3.080440677246378, std=4.606357497008617)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_coms2.average_internal_degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3acc072-9f8f-4f1e-b11b-b86f554d608b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_coms_communities2 = lp_coms2.communities\n",
    "len(lp_coms_communities2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1218d426-1d03-46c4-987c-da912b366969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Label propagation algorithm\n",
      "Transitivity: 0.12165098562689422\n",
      "Hub Dominance: 0.9200157747377216\n",
      "Embeddedness: 0.6787243378122182\n",
      "Conductance: 0.39845183927484856\n",
      "Modularity: 0.205312794249788\n",
      "Internal Edge Density: 0.5728571516606595\n"
     ]
    }
   ],
   "source": [
    "evaluation_algo(G_connected, lp_coms2, 'Label propagation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cab6aee4-833b-4035-9079-f8928f560dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduct_communities_lp_coms2 = [c for c in lp_coms_communities2 if len(c) >= 5]\n",
    "len(reduct_communities_lp_coms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bf95f03-786a-47ef-931e-75f9f2de20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ottieni l'insieme dei nodi che compongono tutte le comunità\n",
    "nodes_in_communities_lp_coms2 = set(node for community in reduct_communities_lp_coms2 for node in community)\n",
    "\n",
    "# 2. Crea un sottografo a partire dal grafo originale\n",
    "subgraph = lp_coms2.graph.subgraph(nodes_in_communities_lp_coms2).copy()\n",
    "\n",
    "# 3. Crea il NodeClustering usando il sottografo\n",
    "reduct_nodeclustering_lp_coms2 = NodeClustering(\n",
    "    communities=reduct_communities_lp_coms2,\n",
    "    graph=subgraph,  # <--- USA il sottografo, non l'intero grafo\n",
    "    method_name=lp_coms2.method_name + \"_reduct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab3f2dca-8f87-49e8-8e7e-1d1ecb825964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Label propagation algorithm\n",
      "Transitivity: 0.3345402104739591\n",
      "Hub Dominance: 0.8217100471954011\n",
      "Embeddedness: 0.887833694856616\n",
      "Conductance: 0.2467346214978971\n",
      "Modularity: 0.1969495200449647\n",
      "Internal Edge Density: 0.03369050040014718\n"
     ]
    }
   ],
   "source": [
    "evaluation_algo(G_connected, reduct_nodeclustering_lp_coms2, 'Label propagation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecac2e2-b2f7-4cac-ba20-5a367bc66ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98689846-ae72-452f-932e-d6d669d65670",
   "metadata": {},
   "source": [
    "### Leiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33c32c89-bc59-4822-9b5b-4a1bcbada033",
   "metadata": {},
   "outputs": [],
   "source": [
    "leiden_coms2 = algorithms.leiden(G_connected, weights='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9499f91-b6ce-47b5-b917-45255a3703e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'initial_membership': None, 'weights': 'weight'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leiden_coms2.method_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d91919ea-c07d-4528-9925-bffe68056a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leiden_coms2.overlap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed2e901b-e8a7-4ce6-ad0c-c2cde5cfebc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FitnessResult(min=1.0, max=28.29230769230769, score=7.1624329908773445, std=8.25787962022157)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leiden_coms2.average_internal_degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cf531b1-5868-4eb7-a9af-4f334e9dec63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leiden_communities2 = leiden_coms2.communities\n",
    "len(leiden_communities2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a7a2301-a4be-4d4b-b755-f5023ce911f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Leiden algorithm\n",
      "Transitivity: 0.2898999261195326\n",
      "Hub Dominance: 0.7870843808923911\n",
      "Embeddedness: 0.6622263106782622\n",
      "Conductance: 0.42104603442607863\n",
      "Modularity: 0.4420023672299359\n",
      "Internal Edge Density: 0.47352326707170533\n"
     ]
    }
   ],
   "source": [
    "evaluation_algo(G_connected, leiden_coms2, 'Leiden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cf34bff-8e51-43a9-b231-f1f0ea86e1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduct_communities_leiden_coms2 = [c for c in leiden_communities2 if len(c) >= 5]\n",
    "len(reduct_communities_leiden_coms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "612798f6-3a08-4af1-81b2-6ca6d4db278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ottieni l'insieme dei nodi che compongono tutte le comunità\n",
    "nodes_in_communities_leiden_coms2 = set(node for community in reduct_communities_leiden_coms2 for node in community)\n",
    "\n",
    "# 2. Crea un sottografo a partire dal grafo originale\n",
    "subgraph = leiden_coms2.graph.subgraph(nodes_in_communities_leiden_coms2).copy()\n",
    "\n",
    "# 3. Crea il NodeClustering usando il sottografo\n",
    "reduct_nodeclustering_leiden_coms2 = NodeClustering(\n",
    "    communities=reduct_communities_leiden_coms2,\n",
    "    graph=subgraph,  # <--- USA il sottografo, non l'intero grafo\n",
    "    method_name=leiden_coms2.method_name + \"_reduct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b715b00a-bf5d-49e6-bc40-f08660f94385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Leiden algorithm\n",
      "Transitivity: 0.535199863605291\n",
      "Hub Dominance: 0.6069250108782603\n",
      "Embeddedness: 0.8091101120214071\n",
      "Conductance: 0.30497143351920736\n",
      "Modularity: 0.42557763654671443\n",
      "Internal Edge Density: 0.028042954593917566\n"
     ]
    }
   ],
   "source": [
    "evaluation_algo(G_connected, reduct_nodeclustering_leiden_coms2, 'Leiden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d01cf45a-518f-4b12-8cb1-5a548a2c7beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_dict = {str(i): community for i, community in enumerate(reduct_communities_leiden_coms2)}\n",
    "\n",
    "# Salvataggio su file JSON\n",
    "with open(output_path+'communities_leiden_general_IG_connected_component_GLOBAL_big_graph.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(communities_dict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad997439-7514-494f-bd6e-5242c6452a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dafb3bed-d0a9-49b8-85ec-6fc90f853a77",
   "metadata": {},
   "source": [
    "## Analisi grafo completo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36c19d1-5da2-4171-b916-6caa9ab2ddc5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Degree2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7560e34a-79d6-4bfd-8859-017aff6c2d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('general_30', 647),\n",
       " ('user_339221', 511),\n",
       " ('user_393808', 454),\n",
       " ('general_14', 379),\n",
       " ('general_33', 334),\n",
       " ('general_39', 311),\n",
       " ('user_370283', 247),\n",
       " ('user_472248', 241),\n",
       " ('user_572416', 233),\n",
       " ('user_158318', 231)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree_sequence = sorted(((n,d) for n, d in g.degree()), reverse=False, key=lambda item: -item[1])\n",
    "degree_sequence[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529a4ba1-2dcd-4920-b5b7-2ea01218450b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Closeness2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c98ed0d-15d7-4dcd-9e82-117470cfa42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness = nx.closeness_centrality(g) # compute the closeness centraliry of all nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5693cef-5e55-4ece-bde5-0d1b7622c48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('general_30', 0.5979390190737289),\n",
       " ('user_339221', 0.5654305548254291),\n",
       " ('user_393808', 0.556157896885333),\n",
       " ('general_14', 0.5337060898950936),\n",
       " ('general_33', 0.522445713584514),\n",
       " ('general_39', 0.5196611927925913),\n",
       " ('user_572416', 0.5109803146948441),\n",
       " ('user_472248', 0.5069947678788947),\n",
       " ('user_370283', 0.5043720985332554),\n",
       " ('user_333699', 0.5038833658796379),\n",
       " ('user_625432', 0.5032331937946318),\n",
       " ('healthy_16', 0.49968702779095414),\n",
       " ('user_474081', 0.49809160305343514),\n",
       " ('user_229789', 0.49793262073519273),\n",
       " ('user_291841', 0.49603271884367534),\n",
       " ('user_158318', 0.493521955319),\n",
       " ('user_426370', 0.49227608102346443),\n",
       " ('user_482802', 0.49041901941633415),\n",
       " ('user_229255', 0.49041901941633415),\n",
       " ('user_366960', 0.49026489653153954),\n",
       " ('user_237813', 0.4901108704880172),\n",
       " ('general_27', 0.48918874279189684),\n",
       " ('user_458439', 0.48903539208882724),\n",
       " ('user_255658', 0.48765955009795525),\n",
       " ('user_351537', 0.4873548580953948),\n",
       " ('general_35', 0.4865947912549466),\n",
       " ('user_327150', 0.48613988805339947),\n",
       " ('user_680020', 0.4844791617277512),\n",
       " ('user_594371', 0.4843287490727597),\n",
       " ('user_670698', 0.4841784297837861)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = [(k, v) for k, v in sorted(closeness.items(), key=lambda item: -item[1])]\n",
    "ranks[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffec7f9-6053-4860-a9c8-782d64b1c4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27d79cf8-caf4-495d-97eb-2fc71fd08047",
   "metadata": {},
   "source": [
    "### Louvain2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b445435-a19c-4842-bcb9-0a43e23e77e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_coms = algorithms.louvain(g, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10ee909e-4fa8-4df9-baa2-2a3a5ffee82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "louvain_coms.overlap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da44b8da-1b8c-48e5-8f9d-da4cc9362913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "louvain_coms.node_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "996b5736-17b9-4e2f-8018-e396f01ee2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "louvain_communities = louvain_coms.communities\n",
    "len(louvain_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8649b2bd-458b-49e5-8e04-c62914ebd2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Louvain algorithm\n",
      "Transitivity: 0.2596907636051376\n",
      "Hub Dominance: 0.8100240589889667\n",
      "Embeddedness: 0.7734458675805869\n",
      "Conductance: 0.28164977923522416\n",
      "Modularity: 0.4835240361830465\n",
      "Internal Edge Density: 0.5411661004742853\n"
     ]
    }
   ],
   "source": [
    "evaluation_algo(g, louvain_coms, 'Louvain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4d86de3-bde4-4813-8ab6-63773434b5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduct_communities_louvain = [c for c in louvain_communities if len(c) >= 5]\n",
    "len(reduct_communities_louvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dfdb872c-b25a-4591-a1f6-ae0eb038d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ottieni l'insieme dei nodi che compongono tutte le comunità\n",
    "nodes_in_communities_louvain = set(node for community in reduct_communities_louvain for node in community)\n",
    "\n",
    "# 2. Crea un sottografo a partire dal grafo originale\n",
    "subgraph = louvain_coms.graph.subgraph(nodes_in_communities_louvain).copy()\n",
    "\n",
    "# 3. Crea il NodeClustering usando il sottografo\n",
    "reduct_nodeclustering_louvain = NodeClustering(\n",
    "    communities=reduct_communities_louvain,\n",
    "    graph=subgraph,  # <--- USA il sottografo, non l'intero grafo\n",
    "    method_name=louvain_coms.method_name + \"_reduct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed591375-288a-4d38-aa0e-13e970e7efea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Louvain algorithm\n",
      "Transitivity: 0.5393577397952858\n",
      "Hub Dominance: 0.6054345840540077\n",
      "Embeddedness: 0.8371568018981421\n",
      "Conductance: 0.25547774661674755\n",
      "Modularity: 0.4765829154130583\n",
      "Internal Edge Density: 0.047037285600438565\n"
     ]
    }
   ],
   "source": [
    "evaluation_algo(g, reduct_nodeclustering_louvain, 'Louvain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262dab0-1ab1-463d-9e81-1f3a236e59cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e481d609-acd5-4281-9d3c-ca6fbccb083e",
   "metadata": {},
   "source": [
    "### Infomap2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "acf3114c-39df-4f30-a1af-6bb5e8f4c132",
   "metadata": {},
   "outputs": [],
   "source": [
    "infomap_coms = algorithms.infomap(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "716da941-1330-4b96-9f66-a779dc412a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infomap_coms.overlap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41a692b2-4bb0-44b9-a133-b1e41809db80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FitnessResult(min=1.0, max=37.55988023952096, score=4.798135549275543, std=7.65661133606267)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infomap_coms.average_internal_degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "312a868e-1cbb-46ff-975d-c1ee4b07ca0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infomap_communities = infomap_coms.communities\n",
    "len(infomap_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc0afb35-4038-49ad-9a34-08516b548fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Infomap algorithm\n",
      "Transitivity: 0.2190525118919456\n",
      "Hub Dominance: 0.9353333040561416\n",
      "Embeddedness: 0.7569022406969304\n",
      "Conductance: 0.38616265977676095\n",
      "Modularity: 0.4441653586311656\n",
      "Internal Edge Density: 0.46183446856745125\n"
     ]
    }
   ],
   "source": [
    "evaluation_algo(g, infomap_coms, 'Infomap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c072947-35f0-49d7-ac41-eb9f9497b519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduct_communities_infomap = [c for c in infomap_communities if len(c) >= 5]\n",
    "len(reduct_communities_infomap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16fdec28-3992-4599-874b-04192c3ea4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ottieni l'insieme dei nodi che compongono tutte le comunità\n",
    "nodes_in_communities_infomap = set(node for community in reduct_communities_infomap for node in community)\n",
    "\n",
    "# 2. Crea un sottografo a partire dal grafo originale\n",
    "subgraph = infomap_coms.graph.subgraph(nodes_in_communities_infomap).copy()\n",
    "\n",
    "# 3. Crea il NodeClustering usando il sottografo\n",
    "reduct_nodeclustering_infomap = NodeClustering(\n",
    "    communities=reduct_communities_infomap,\n",
    "    graph=subgraph,  # <--- USA il sottografo, non l'intero grafo\n",
    "    method_name=infomap_coms.method_name + \"_reduct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b54faf8-c2a5-4c13-92d8-c15308156849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Infomap algorithm\n",
      "Transitivity: 0.38656325627990396\n",
      "Hub Dominance: 0.8858823012755439\n",
      "Embeddedness: 0.7883650652821645\n",
      "Conductance: 0.4051329850402223\n",
      "Modularity: 0.4386868978236488\n",
      "Internal Edge Density: 0.09931572884452182\n"
     ]
    }
   ],
   "source": [
    "evaluation_algo(g, reduct_nodeclustering_infomap, 'Infomap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6b3e79-8cb7-4c63-ae3c-f1783591f67c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f5ac653-fed4-4d80-b1a6-acc078829528",
   "metadata": {},
   "source": [
    "### Label propagation2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc4c374d-bb25-4116-96d8-ec74b9107cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_coms = algorithms.label_propagation(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "048d3a2c-228c-4e99-af13-f3b39ec84af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_coms.overlap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6f48936a-a753-4e14-b0e2-b446c641a41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FitnessResult(min=1.0, max=26.328827037773358, score=3.2755101510944584, std=5.3519323926207765)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_coms.average_internal_degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9f8a7d14-c5e4-47c8-bdc9-b40d5ea97b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_coms_communities = lp_coms.communities\n",
    "len(lp_coms_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e303f357-e4aa-4db5-a946-a45ead30c9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Label propagation algorithm\n",
      "Transitivity: 0.12066129627007573\n",
      "Hub Dominance: 0.9261497110770653\n",
      "Embeddedness: 0.7228209973281883\n",
      "Conductance: 0.34376237113908503\n",
      "Modularity: 0.297516460360739\n",
      "Internal Edge Density: 0.61776179356813\n"
     ]
    }
   ],
   "source": [
    "evaluation_algo(g, lp_coms, 'Label propagation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "565cfca8-66cc-476e-b6e4-3cde8407f21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduct_communities_lp_coms = [c for c in lp_coms_communities if len(c) >= 5]\n",
    "len(reduct_communities_lp_coms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af4ab513-26c5-4d19-a370-3b5659fe0d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ottieni l'insieme dei nodi che compongono tutte le comunità\n",
    "nodes_in_communities_lp_coms = set(node for community in reduct_communities_lp_coms for node in community)\n",
    "\n",
    "# 2. Crea un sottografo a partire dal grafo originale\n",
    "subgraph = lp_coms.graph.subgraph(nodes_in_communities_lp_coms).copy()\n",
    "\n",
    "# 3. Crea il NodeClustering usando il sottografo\n",
    "reduct_nodeclustering_lp_coms = NodeClustering(\n",
    "    communities=reduct_communities_lp_coms,\n",
    "    graph=subgraph,  # <--- USA il sottografo, non l'intero grafo\n",
    "    method_name=lp_coms.method_name + \"_reduct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f4546b89-d9da-4ae9-b009-b8bc73a2e799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Label propagation algorithm\n",
      "Transitivity: 0.36198388881022714\n",
      "Hub Dominance: 0.8176648195057061\n",
      "Embeddedness: 0.8944317128062268\n",
      "Conductance: 0.2322208202333149\n",
      "Modularity: 0.28731672194824476\n",
      "Internal Edge Density: 0.04936381207693903\n"
     ]
    }
   ],
   "source": [
    "evaluation_algo(g, reduct_nodeclustering_lp_coms, 'Label propagation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4740da0f-08f1-43b4-bae7-ffb6f35f1ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2d72d1c-30fb-453e-b874-f0af740d2767",
   "metadata": {},
   "source": [
    "### Leiden2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "49a0c310-8857-4814-a4a2-8eb66618b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "leiden_coms = algorithms.leiden(g,weights='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2eae3a5e-ab84-436a-8dfd-ca7dc5a058fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'initial_membership': None, 'weights': 'weight'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leiden_coms.method_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ade0c3d0-bbc8-4284-9214-b013a8f8ebad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leiden_coms.overlap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "65c5209c-ed7a-4db1-b6b7-36d319c94230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FitnessResult(min=1.0, max=28.191570881226053, score=6.472159904946781, std=8.224267781138154)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leiden_coms.average_internal_degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bdf856c8-d836-470d-8ab5-25702c396e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leiden_communities = leiden_coms.communities\n",
    "len(leiden_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "38d1f942-65ee-47d7-8de8-a69cc3cd2db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Leiden algorithm\n",
      "Transitivity: 0.2470670654817392\n",
      "Hub Dominance: 0.8254879558521387\n",
      "Embeddedness: 0.7381159147095994\n",
      "Conductance: 0.32458718513289775\n",
      "Modularity: 0.4855365081536149\n",
      "Internal Edge Density: 0.5693813444761927\n"
     ]
    }
   ],
   "source": [
    "evaluation_algo(g, leiden_coms, 'Leiden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bd8184ee-30ef-408f-b3a6-29f9477b0904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduct_communities_leiden_coms = [c for c in leiden_communities if len(c) >= 5]\n",
    "len(reduct_communities_leiden_coms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16acbf4e-0955-4612-9cc5-ac7dea267b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ottieni l'insieme dei nodi che compongono tutte le comunità\n",
    "nodes_in_communities_leiden_coms = set(node for community in reduct_communities_leiden_coms for node in community)\n",
    "\n",
    "# 2. Crea un sottografo a partire dal grafo originale\n",
    "subgraph = leiden_coms.graph.subgraph(nodes_in_communities_leiden_coms).copy()\n",
    "\n",
    "# 3. Crea il NodeClustering usando il sottografo\n",
    "reduct_nodeclustering_leiden_coms = NodeClustering(\n",
    "    communities=reduct_communities_leiden_coms,\n",
    "    graph=subgraph,  # <--- USA il sottografo, non l'intero grafo\n",
    "    method_name=leiden_coms.method_name + \"_reduct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05887a1e-7415-4e92-a613-85e954680fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Leiden algorithm\n",
      "Transitivity: 0.5470770735667083\n",
      "Hub Dominance: 0.6135804736725928\n",
      "Embeddedness: 0.8218995254283984\n",
      "Conductance: 0.2801233249031169\n",
      "Modularity: 0.4665814203862123\n",
      "Internal Edge Density: 0.04648726276871241\n"
     ]
    }
   ],
   "source": [
    "evaluation_algo(g, reduct_nodeclustering_leiden_coms, 'Leiden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c682a338-1e8c-42c4-81bf-a526ace5c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_dict = {str(i): community for i, community in enumerate(reduct_communities_leiden_coms)}\n",
    "\n",
    "# Salvataggio su file JSON\n",
    "with open(output_path+'communities_leiden_general_IG_all_graph_GLOBAL_big_graph.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(communities_dict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb2a9d-6308-44de-8d08-6a90a6f6dbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a83906-6097-463e-8ba0-263d7400dde6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206cca58-b806-4349-9813-2b07b8bf25d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde85a1e-dce5-4f7d-a5b1-64b8bafd017b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928d8b09-2d40-4d75-80fe-b41a8cb6f265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ae77ea-8651-440e-9e95-604e73a5cfee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
